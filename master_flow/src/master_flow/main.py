#!/usr/bin/env python
import json
import sys
import asyncio
from crewai.flow.flow import Flow, start, listen, router, or_
from crewai.flow.persistence import persist

# Import the SystemState from the model folder
from master_flow.model.system_state import SystemState

# Import the crews
from master_flow.crews.macro_planning_crew.macro_crew import MacroPlanningCrew
from master_flow.crews.micro_learning_crew.micro_crew import MicroLearningCrew

@persist()
class MasterFlow(Flow[SystemState]):
    
    @start()
    def execute_macro_planning(self):
        print(f"--- MACRO PLANNING CREW ACTIVATED ---")
        
        inputs = {
            "topic": self.state.topic,
            "experience": self.state.experience,
            "goal": self.state.goal,
            "constraints": self.state.constraints or "None specified."
        }
        
        # Kickoff the Crew. Runs Architect only now.
        result = MacroPlanningCrew().crew().kickoff(inputs=inputs)
        
        import os
        debug_info = {
            "pydantic_output": getattr(result, "pydantic", None) and getattr(result.pydantic, "model_dump", lambda: None)() if getattr(result, "pydantic", None) else None,
            "json_dict_output": getattr(result, "json_dict", None),
            "raw_output": getattr(result, "raw", None),
            "tasks_output": [
                {
                    "raw": getattr(t, "raw", None),
                    "json_dict": getattr(t, "json_dict", None),
                    "pydantic": getattr(t, "pydantic", None) and getattr(t.pydantic, "model_dump", lambda: None)() if getattr(t, "pydantic", None) else None
                } for t in getattr(result, "tasks_output", [])
            ]
        }
        
        # Save trace to help debug empty arrays
        debug_path = os.path.join(os.path.dirname(__file__), "../../api/temp_macro_crew_debug.json")
        try:
            with open(debug_path, "w") as f:
                json.dump(debug_info, f, indent=2, default=str)
        except Exception as e:
            print(f"Warning: Could not write debug info to {debug_path}: {e}")

        # Extract the Architect's blueprint directly with robust fallbacks
        try:
            if result.pydantic:
                self.state.blueprint = result.pydantic.model_dump()
            elif result.json_dict:
                self.state.blueprint = result.json_dict
            else:
                raw_text = getattr(result, "raw", "")
                if raw_text:
                    import re
                    match = re.search(r'\{.*\}', raw_text, re.DOTALL)
                    if match:
                        self.state.blueprint = json.loads(match.group(0))
                    else:
                        self.state.blueprint = {"nodes": []}
                else:
                    self.state.blueprint = {"nodes": []}
        except Exception as e:
            print(f"Warning: Could not extract architect blueprint. {e}")
            self.state.blueprint = {"nodes": []}
            
        # Log final blueprint state assigned to the master flow
        final_blueprint_path = os.path.join(os.path.dirname(__file__), "../../api/temp_macro_blueprint_final.json")
        try:
            with open(final_blueprint_path, "w") as f:
                json.dump(self.state.blueprint, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not write final blueprint to {final_blueprint_path}: {e}")

        print("--- BLUEPRINT GENERATED BY ARCHITECT ---")

    @listen(execute_macro_planning)
    async def process_all_nodes(self):
        """Process all nodes concurrently using async kickoff."""
        blueprint_data = self.state.blueprint # This is the dict saved from Macro Crew
        pending_nodes = blueprint_data.get("nodes", [])
        
        async def process_single_node(node):
            print(f"--- GENERATING CONTENT FOR (ASYNC): {node['title']} ---")
            inputs = {
                "macro_title": node['title'],
                "node_id": node['node_id'],
                "micro_topics_list": ", ".join(node['suggested_micro_topics']),
                "experience": self.state.experience,
                "goal": self.state.goal
            }
            try:
                result = await MicroLearningCrew().crew().akickoff(inputs=inputs)
                if result.pydantic:
                    return result.pydantic.model_dump()
                elif result.json_dict:
                    return result.json_dict
                else:
                    print(f"Warning: No valid pydantic output from Micro Crew for {node['title']}")
                    return None
            except Exception as e:
                print(f"Error processing node {node['title']}: {e}")
                return None

        results = await asyncio.gather(*[process_single_node(n) for n in pending_nodes])
        self.state.completed_modules = [r for r in results if r is not None]

    @listen(process_all_nodes)
    def finish_course(self):
        reply = "Your complete, personalized micro-learning course is ready!"
        self.state.chat_history.append({"role": "assistant", "content": reply})
        return {
            "status": "complete", 
            "reply": reply, 
            "blueprint": self.state.blueprint,
            "course_content": self.state.completed_modules
        }

def kickoff():
    master_flow = MasterFlow()
    master_flow.kickoff()

def plot():
    master_flow = MasterFlow()
    master_flow.plot()

if __name__ == "__main__":
    kickoff()
